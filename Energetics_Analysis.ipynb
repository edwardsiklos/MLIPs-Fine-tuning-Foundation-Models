{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505210e5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # ------- STRUCTURE TEST SET GENERATOR -----------\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from ase.io import read, write\n",
    "import re\n",
    "\n",
    "def import_simulation_data(directory):\n",
    "\n",
    "    dump_file_name = re.compile(r\"^dump_custom\\.C\\.(\\d+)\\.dat$\") # Dump file regex\n",
    "    unique_key_pattern = re.compile(\n",
    "        r'^(?P<element_symbol>[A-Za-z]{1,6})_'          # e.g. C\n",
    "        r'(?P<potential_name>[^_]+)_'                   # e.g. GAP17\n",
    "        r'(?P<simulation_type>[^_]+)_'                  # e.g. NVT\n",
    "        r'(?P<num_atoms>\\d+)_'                          # e.g. 64\n",
    "        r'(?P<density>[\\d.eE+-]+)_'                     # e.g. 1.5 or 1.85e+00\n",
    "        r'(?P<run>\\d+)'                                 # e.g. 1 (run number) \n",
    "        )\n",
    "     \n",
    "    directory = Path(directory)\n",
    "\n",
    "    imported_simulation_files = defaultdict(list) # Imported files dictionary\n",
    "\n",
    "    imported_files_counter = 0\n",
    "    skipped_files_counter = 0\n",
    "\n",
    "    for path in directory.rglob(\"*\"):\n",
    "        \n",
    "        if not path.is_file(): # Filters for files not directories\n",
    "            continue\n",
    "\n",
    "        m = dump_file_name.match(path.name) # Enforce dump_file file naming\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        parent = path.parent\n",
    "        \n",
    "        if parent.name != \"NVT\": # Enforce NVT file naming\n",
    "            skipped_files_counter += 1\n",
    "            print(f\"ERROR: Parent directory for {path}, {parent} is not equal to NVT\")\n",
    "            continue\n",
    "\n",
    "        grandparent = parent.parent\n",
    "    \n",
    "        if not unique_key_pattern.match(grandparent.name): # Enforce unique_key file naming\n",
    "            skipped_files_counter += 1\n",
    "            print(f\"ERROR: Invalid unique_key name format '{grandparent.name}'\")\n",
    "            continue\n",
    "\n",
    "        if not grandparent.name: # Protect against missing grandparent\n",
    "            skipped_files_counter += 1\n",
    "            print(f\"ERROR: No grandparent directory for {path}\")\n",
    "            continue\n",
    "\n",
    "        unique_key = grandparent.name\n",
    "        numeric_index = int(m.group(1))\n",
    "\n",
    "        imported_simulation_files[unique_key].append((numeric_index, path))\n",
    "        imported_files_counter += 1\n",
    "\n",
    "    # sort each list by numeric index and drop the numeric index in final structure\n",
    "    sorted_imported_simulation_files = {}\n",
    "\n",
    "    for key, items in imported_simulation_files.items():\n",
    "        items.sort(key=lambda pair: pair[0])  # sort by numeric_index\n",
    "        paths_sorted = [p for _, p in items]\n",
    "        sorted_imported_simulation_files[key] = paths_sorted\n",
    "\n",
    "    if imported_files_counter:\n",
    "        print(f\"Imported {imported_files_counter} dump files\")\n",
    "    if skipped_files_counter:\n",
    "        print(f\"Skipped {skipped_files_counter} dump files due to errors\")\n",
    "\n",
    "    return sorted_imported_simulation_files\n",
    "\n",
    "# Writes cif files from ALL imported LAMMPS dump files\n",
    "def write_cif_files(data_dict, out_dir, timestep):\n",
    "\n",
    "    timestep_fs = timestep * 100\n",
    "    padded_timestep = f\"{timestep_fs:05d}\"\n",
    "\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    files_written_counter = 0\n",
    "\n",
    "    for unique_key, dump_files in data_dict.items():\n",
    "        \n",
    "        atoms = read(dump_files[timestep])\n",
    "        atoms.set_chemical_symbols([element] * len(atoms))\n",
    "\n",
    "        file_name = f\"{unique_key}_{padded_timestep}.cif\"\n",
    "        file_path = Path(out_dir) / file_name\n",
    "\n",
    "        write(file_path, atoms)\n",
    "\n",
    "        files_written_counter += 1\n",
    "\n",
    "    if files_written_counter:\n",
    "        print(f\"{files_written_counter} cif files written to {out_dir.name}\")\n",
    "# -----------------------------------------------\n",
    "\n",
    "simulation_dir = \"LAMMPS_simulations/Element: Carbon/Potential: GAP17/Type: NVT/Atoms: 216\"\n",
    "\n",
    "element = \"C\" # LAMMPS dump files only contain a \"type\" index, this must be assigned to a given element\n",
    "\n",
    "imported_simulation_files = import_simulation_data(simulation_dir)\n",
    "\n",
    "amorphous_structures = write_cif_files(imported_simulation_files, \n",
    "                                       out_dir =\"Carbon_Structures/Amorphous\", timestep=95)\n",
    "\n",
    "liquid_structures = write_cif_files(imported_simulation_files, \n",
    "                                       out_dir =\"Carbon_Structures/Liquid\", timestep=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63acf77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 2 structures from Carbon_Structures/Crystalline/Downloaded\n",
      "\n",
      "Skipped 6 existing traj files\n"
     ]
    }
   ],
   "source": [
    "# Crystal Structure Analysis\n",
    "\n",
    "# 1. import crystal structure\n",
    "# 2. relax using BFGS algorithm with a model\n",
    "# 3. calculate energy relative to isolated atom\n",
    "# 4  calculate lattice params and avg bond lengths\n",
    "\n",
    "from pathlib import Path\n",
    "from ase import atoms\n",
    "from ase.io import read\n",
    "from ase.optimize import BFGS\n",
    "from ase.filters import UnitCellFilter\n",
    "from graph_pes.models import load_model\n",
    "from graph_pes.utils.calculator import merge_predictions\n",
    "\n",
    "# model: path to model \n",
    "def energetics_calculator(in_dir, relaxed_dir, path_to_models, path_to_reference_structure, OVERWRITE):\n",
    "\n",
    "    # Import structures from in_dir\n",
    "    in_dir = Path(in_dir)\n",
    "    downloaded_structures = []\n",
    "\n",
    "    imported_structures_counter = 0\n",
    "\n",
    "    for file in in_dir.rglob('*'):\n",
    "\n",
    "        structure = read(file)\n",
    "        downloaded_structures.append((file, structure))\n",
    "        imported_structures_counter += 1\n",
    "    \n",
    "    print(f\"Imported {imported_structures_counter} structures from {in_dir}\\n\")\n",
    "    \n",
    "    existing_traj_files_counter = 0\n",
    "    # Import model\n",
    "    for path_to_model in path_to_models:\n",
    "\n",
    "        model = load_model(Path(path_to_model))\n",
    "        calculator = model.ase_calculator()\n",
    "\n",
    "        # Relax structures\n",
    "        # Write trajectories and final frame \n",
    "        counter = 0\n",
    "        \n",
    "        # Loop over all structures\n",
    "        for file, structure in downloaded_structures:\n",
    "\n",
    "            traj_dir = Path(relaxed_dir) / \"Trajectories\"\n",
    "            traj_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            final_traj_dir = Path(relaxed_dir)/ \"Final Trajectory Frame\"\n",
    "            final_traj_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            traj_out_path = traj_dir / f\"{Path(path_to_model).stem}_relaxed_{file.stem}.traj\"\n",
    "            final_traj_out_path = final_traj_dir / f\"{Path(path_to_model).stem}_relaxed_{file.stem}.cif\"\n",
    "\n",
    "            structure.calc = calculator\n",
    "            \n",
    "\n",
    "            if traj_out_path.exists() and not OVERWRITE:\n",
    "                existing_traj_files_counter +=1\n",
    "                continue\n",
    "            \n",
    "            # Relax structure with BFGS (allowing for cell params to change)\n",
    "            ucf = UnitCellFilter(structure)\n",
    "            opt = BFGS(ucf,\n",
    "                    logfile=None,             \n",
    "                    trajectory=traj_out_path)\n",
    "            opt.run(fmax=0.02, steps=200)\n",
    "\n",
    "\n",
    "            # Write final relaxed structure\n",
    "            final_structure = read(traj_out_path, index=-1)\n",
    "            write(final_traj_out_path, final_structure)\n",
    "\n",
    "            # Calculate energy of final structure\n",
    "            calculator.calculate(final_structure, properties=[\"energy\", \"forces\"])\n",
    "            raw_energy = calculator.results.get(\"energy\", None)\n",
    "            forces = calculator.results.get(\"forces\", None)\n",
    "\n",
    "            # Calculate energy of reference structure\n",
    "            reference_calc = model.ase_calculator()\n",
    "            ref_struct = read(Path(path_to_reference_structure))\n",
    "            reference_calc.calculate(ref_struct, properties = [\"energy\"])\n",
    "            ref_energy = reference_calc.results.get(\"energy\", None)\n",
    "\n",
    "            # Relative energy\n",
    "            relative_energy = raw_energy - ref_energy\n",
    "            \n",
    "            # Lattice params and bond lengths\n",
    "            a, b, c, alpha, beta, gamma = final_structure.cell.cellpar()\n",
    "        \n",
    "            # Print results\n",
    "            print(\n",
    "                  f\"{Path(path_to_model).name} Results for {file.stem}:\"\n",
    "                  f\"\\nLattice parameters = ({a},{b},{c}) ({alpha},{beta},{gamma})\"\n",
    "                  f\"\\nReference energy = {ref_energy}\"\n",
    "                  f\"\\nRaw energy = {raw_energy}\"\n",
    "                  f\"\\nRelative energy = {relative_energy}\"\n",
    "                  f\"\\nForces = {forces}\\n\"\n",
    "                    )\n",
    "            \n",
    "            counter += 1\n",
    "\n",
    "        if counter:\n",
    "            print(f\"Relaxed and analyzed {counter} structures with {Path(path_to_model).name}\\n\")\n",
    "\n",
    "    print(f\"Skipped {existing_traj_files_counter} existing traj files\")\n",
    "\n",
    "models_to_analyse = [\"MACE_Models/medium-0b3.pt\", \n",
    "                     \"MACE_Models/medium-mpa-0.pt\",\n",
    "                     \"MACE_Models/medium-omat-0.pt\"]    \n",
    "\n",
    "set_OVERWRITE = False\n",
    "\n",
    "energetics_calculator(\n",
    "                    in_dir=\"Carbon_Structures/Crystalline/Downloaded\",\n",
    "                    relaxed_dir=\"Carbon_Structures/Crystalline/Relaxed\",\n",
    "                    path_to_models= models_to_analyse,\n",
    "                    path_to_reference_structure=\"Carbon_Structures/isolated_C.cif\",\n",
    "                    OVERWRITE=set_OVERWRITE\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb868ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created isolated carbon atom\n",
    "from ase import Atoms\n",
    "from ase.io import write\n",
    "\n",
    "# One carbon atom in a large cubic box\n",
    "atoms = Atoms('C', positions=[[15, 15, 15]], cell=[30, 30, 30], pbc=False)\n",
    "\n",
    "write(\"isolated_C.cif\", atoms)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-pes-mace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
